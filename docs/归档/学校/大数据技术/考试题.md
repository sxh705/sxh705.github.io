# 考试2021

## 4.1试述大数据的四种计算模式，并列举一种代表产品

### 批处理计算

解释：针对大规模数据的批量处理

代表产品：MapReduce Spark

### 流计算

针对流数据的实时计算

Storm

### 图计算

针对大规模图数据结构的处理

Pregel GraphX

### 查询分析计算

大规模数据的存储管理，查询分析

Hive Dremel



## 4.2 Hadoop2.0的改进

在 Hadoop1.x 中的 NameNode 只可能有一个，虽然可以通过SecondaryNameNode 与 NameNode进行数据同步备份，

但是总会存在一定的时延，如果 NameNode 挂掉，但是如果有部分数据还没有同步到SecondaryNameNode 上，还是可能会存在着数据丢失的问题。

在Hadoop2.X 中， HDFS 的变化，主要体现在增强了 NameNode 的水平扩及可用性，可以同时部署多个NameNode ，这些NameNodes 之间是相互独立，也就是说他们不需要相互协调， DataNode 同时在所有NameNodes 注册，做为他们共有的存储节占并向定时向所有的这些NameNodes  发送心跳块使用情况的报告，并处理所有 NameNodes 向其发送的指令



## 4.3 描述Spark生态系统包含的组件及应用场景

Spark Core 是整个 BDAS 生态系统的核心组件，是一个分布式大数据处理框架。Spark Streaming 是一个对实时数据流进行高吞吐、高容错的流式处理系统，可以对多种数据源（如 Kafka 、Flume 、 Twitter 和 ZeroMQ 等）进行类似 Map 、 Reduce 和 Join 等复杂操作，并将结果保存到外部文件系统、数据库或应用到实时仪表盘。Shark 即 Hive on Spark, 本质上是通过 Hive 的 HQL 进行解析，把 HQL 翻译成 Spark 上对应的 RDD 操作，然后通过 Hive 的 Metadata 获取数据库里的表信息，实际为 HDFS 上的数据和文件，最后由 Shark 获取并放到Spark 上运算。BlinkDB 是一个用于在海量数据上运行交互式 SQL 查询的大规模并行查询引擎，它允许用户通过权衡数据精度来提升查询响应时间，其数据的精度被控制在允许的误差范围内。MLBase 是 Spark 生态系统中专注于机器学习的组件，它的目标是让机器学习的门槛更低，让一些可能并不了解机器学习的用户能够方便地使用MLBase。

MLBase 分为四个部分MLRuntime 、MLlib 、 ML和 MLOptimizer。



## 4.4 NoSql数据库的四大类型

一、键值 (Key-Value) 数据库

键值数据库就像在传统语言中使用的哈希表。你可以通过key来添加、查询或者删除数据，鉴于使用主键访问，所以会获得不错的性能及扩展性。

二、面向文档 (Document-Oriented) 数据库

面向文档数据库会将数据以文档的形式储存。每个文档都是自包含的数据单元，是一系列数据项的集合。每个数据项都有一个名称与对应的值，值既可以是简单的数据类型，如宇符串、数字和日期等;也可以是复杂的类型，如有序列表和关联对象。数据存储的最小位是文档，同一个表中存储的文档属性可以是不同的，数据可以使用XML、JSON或者JSONB等多种形式存储。

三、列存储 (Wide Column Store/Column-Family) 数据库

列存储数据库将数据储存在列族 (column family) 中，一个列族存储经常被一起查询的相关数据。举个例子，如果我们有一个Person类，我们通常会一起查询他们的姓名和年齿而不是薪资。这种情况下，姓名和年龄就会被放入一个列族中，而薪资则在另一个列族

四、图 (Graph-Oriented) 数据库

图数据库允许我们将数据以图的方式储存。实体会被作为顶点，而实体之间的关系则会被作为边。比如我们有三个实体，Steve Jobs、Apple和Next，则会有两个“Foundedby”的边将Apple和Next连接到Steve Jobs。



## 4.5 简述HDFS的第二名称节点辅助名称节点进行FsImage和EditLog合并的过程。

四5
名称节点运行期间，HDFS内的更新操作被写入到EditLog文件中，随着更新操作的不断发生，EditLog也将不断变大。名称节点在每次重启时，将Fslmage加载到内存中，再逐条执行EditLog中的记录，使Fslmage保持最新状态。每隔一段时间.
SecondarvNameNode会与NameNode进行通信，请求
NameNode停止使用EditLog文件，让NameNode将这之后新到达的写操作写入到一个新的文件EditLog.new中;然后 SecondaryNameNode将EditLog、Fslmage拉回至本地，加载到内存中-即将Fslmage加载到内存中，再逐条执行EditLog中的记录，使Fslmage保持最新。



## 4.6对比MapReduce Spark Streaming Storm实时响应的能力

四6Hadoop MapReduce 是三者中出现最早，知名度最大的分布式计算框架。主要适用于大批量的集群任务由于是批量执行，故时效性偏低

Spark Streaming 保留了 HadoopMapReduce 的优点，而且在时效性上有了很大提高，中间结果可以保存在内存中，从而对需要迭代计算和有较高时效性要求的系统提供了很好的支持，多用于能容忍小延时的推荐与计算系统。

Storm一开始就是为实时处理设计，因此在实时分析/性能监测等需要高时效性的领域广泛采用。



## 5

配置SSH无密码 `ssh-keygen -t rsa`

环境变量生效` source /etc/profile`

slave文件的文本：`四行`

分别是

```
4.
- core.site.xml
- hdfs.site.xml
- mapreduce.site.xml
- yarm.site.xml
```

```
// 5.
<configuration>  
  <property>  
    <name>fs.defaultFS</name>  
    <value>hdfs://192.168.1.100:2200</value>  
  </property>  
</configuration>
```

```
//6. yarn-site.xml
```

8.

名称节点格式化`hdfs namenode -format`

启动hdfs`start-dfs.sh`

启动yarn`start-yarn.sh`

9.

1200



六

1.

完成hdfs shell命令

hadoop fs -mkdir /user/hadoop/dir1

hadoop fs -put File.txt /user/hadoop/dir1

hdfs dfs -cat hdfs://user/hadoop/dir1/File.txt



2.

`put 'student', '9528', 'course:math', '88'`

`get 'student', '9528', 'course:math'`





3.(2_1)

基于Hadoop MapReduce的程序

6-10

6 `public static class ScoreMapper extends Mapper<Object, Text, Text, IntWritable>`

7 `stu_name, score`

8 ` sum += val.get();  `

9 `ScoreSumMapper.class`

10 `ScoreSumReducer.class`



