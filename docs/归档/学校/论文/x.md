


网络高速缓存设计的实用优化方法
摘要-- 在任何缓存系统中，接纳和剔除策略都决定了在发生缺失时从缓存中添加和删除哪些内容。通常情况下，制定这些策略的目的是为了减少滞留并提高命中概率。然而，不同内容的高命中概率的效用可能会有所不同。例如，当必须满足服务水平协议或某些内容比其他内容更难获取时，就会出现这种情况。在本文中，我们提出了效用驱动型缓存，即为每个内容关联一个效用，该效用是相应内容命中概率的函数。我们提出了优化问题，其目标是最大化所有内容的效用总和。这些问题根据缓存容量约束的严格程度而有所不同。我们的框架使我们能够反向设计经典的替换策略，如 LRU 和 FIFO，计算它们最大化的效用函数。我们还开发了在线算法，服务提供商可利用这些算法根据任意效用函数实施各种缓存策略。
I. 导言 据预测，过去几年数据流量的增长势头将更加强劲，全球互联网流量将达到据估计，2019 年的数据流量将达到 2005 年的 64 倍。数据流量增长的主要原因是通过蜂窝网络传输视频点播内容。然而，增加频谱或部署更多基站等传统方法不足以应对预计的流量增长, 。在当前和未来的互联网架构提案中，缓存被认为是提高网络应用性能的最有效手段之一。通过使内容更接近用户，缓存大大减少了网络带宽的使用、服务器负载和感知到的服务延迟。
由于云计算的趋势、新内容发布者和消费者的产生，互联网正日益成为一个异构环境，不同的内容类型有不同的服务质量要求，具体取决于内容发布者/ 消费者。
预计在不久的将来，随着智能楼宇和网络家电的发展，新的数据源将不断涌现，内容和消费者也将更加多样化
 。服务期望的日益多样化要求内容交付基础设施在不同应用和内容类别之间提供差异化服务。此外，服务还具有经济价值。因此，服务差异化不仅能带来重要的技术收益，还能带来显著的经济效益。
尽管对通信网络中公平、高效的带宽共享算法的设计和实施进行了大量研究，但很少有人关注在网络和网络缓存中提供多级服务。现有的少量研究主要集中在设计缓存空间分区控制器、、针对特定内容类别的偏向替换策略或使用多级缓存。这些技术要么需要额外的控制器来保证公平性，要么不能有效利用缓存存储。
此外，传统的缓存管理策略以强耦合的方式处理不同的内容，这使得服务提供商难以实施差异化服务，内容发布商也难以对通过内容分发网络分发的内容进行估值。
在本文中，我们提出了一种效用驱动型缓存框架，其中每个内容都有一个相关效用，内容在缓存中的存储和管理是为了使所有内容的总效用最大化。可以选择效用来权衡用户满意度和在缓存 中存储内容的成本。我们借鉴了实时缓存的分析结果 ，为 单个内容设计了与效用相关联的缓存。效用函数还具有隐含的公平性概念，它规定了每个内容在缓存 中的停留时间。请注意，这种公平性概念可应用于网络缓存，在网络
缓存中，移动设备或接入点充当缓存，以较低的延迟向用户高效地传送内容。我们的框架使我们能够开发缓存管理的在线算法，并证明这些算法能达到最佳性能。
我们的框架对分布式定价和控制机制有影响，因此非常适合设计缓存市场经济模型。
我们在本文中的主要贡献可概括如下：
我们制定了一个基于效用的优化框架，在服务提供商的缓冲容量限制下最大化内容发布者的总效用。我们表明，现有的缓存策略(如 LRU、LFU 和 FIFO)可在此框架内建模为效用驱动缓存。
通过将 LRU 和 FIFO 缓存政策逆向工程为效用最大化问题，我们发现与缓存容量约束相对应的拉格朗日乘数与缓存特征时间的概念有关，该概念于 1977 年由 Fagin作为窗口大小首次提出，并于 2001 年由 Che 等人重新发现。
我们开发了管理高速 缓存 的在线算法，并利用Lyapunov 函数证明了这些算法对最优解的收敛性。
我们表明，我们的框架可用于基于收入的模型，在这种模型中，内容发布商会对服务提供商设定的价格做出反应，而不会透露其效用函数。
我们使用不同的效用函数和不同的公平概念进行了模拟，以展示我们在线算法的效率。
本文的其余部分安排如下 。我们在下一节回顾了相关工作。第三节解释本文考虑的网络模型，第四节介绍我们设计效用最大化缓存的方法。在第五节，我们阐述了效用函数对公平性的影响；在第六节，我们推导了 LRU 和 FIFO 缓存最大化的效用 函数 。第七节，我们开发了实现效用最大化缓存的在线算法。我们在第八节介绍了仿真结果，并在第九节讨论了缓存效用最大化框架的前景和意义。最后，我们在第 X 节总结本文。
II. 相关工作
A. 网络实用性和服务差异化效用函数已被广泛应用于计算机网络的建模和 控制，从队列的稳定性分析到网络资源分配中的公平性和服务差异化研究；参见 、 及其中的参考文献。Kelly 
首次将速率分配问题表述为实现用户总效用最大化的问题，并描述了如何通过让单个用户控制其传输速率来实现全网最优速率分配。Kelly 等人 的研究首次提出了一般拓扑网络拥塞控制算法行为的数学模型和分析。此后，人们开始广泛研究如何推广和应用 Kelly 的网络效用最大化框架，对各种网络协议和架构进行建模和分析。这一框架已被用于研究网络路由、吞吐量最大化、动态功率分配和能量收集网络中的调度等等。
网络缓存管理中的服务差异化问题也得到了广泛的研究(例如，见及其中的参考文献)。不过，有关这一主题的大多数研究都使用缓存分区作为提供服务差异化的手段-。Ma 和 Towsley 最近提议使用效用函数来设计合同，使服务提供商能够将缓存货币化。
我们在之前的工作的基础上，引入了一种效用驱动型方法，根据与每个内容相关的效用来管理缓存内容。
在和中 ，Neglia 等人扩展了本文提出的框架，以处理不同大小的内容，并使用跟踪驱动的模拟来评估他们的算法。
B. 实时缓存在 TTL 缓存中，内容会在定时器到期时被驱逐，这种缓存从互联网诞生之初就开始使用，域名系统
就是其中的一个重要应用。最近，TTL 缓存重新受到人们的欢迎，这主要是因为在缓存分析中采用了一种通用方法，这种方法也可用于 对基于替换的缓存策略进行建模。TTL 缓存和基于替换
的策略之间的联系，Fagin和 Che 等人分别通过赢道大小和缓存特征时间的概念为 LRU 策略建立了联系。特征时间在理论上是合理的，并扩展到其他缓存策略，如 FIFO 和 RANDOM 。这一联系被进一步证实适用于比泊松过程更一般的到达模型 。在过去几年中，已经提出了几种精确和近似的分析方法，用于单独模拟单个高速缓存，以及使用 TTL 框架模拟高速缓存网络
, 。最近，Ferragut 等人、 提出了一个优化问题，以确定如何选择最大化命中概率的定时器，并确定了重尾到达情况下基于 TTL 的最优策略结构。
Neglia 等人 研究了具有线性成本函数的内容检索缓存问题，并提出了解决线性效用最大化问题的动态策略。在中，Neglia 等人使用效用最大化方法提出了一种新的缓存替换策略，该策略利用了内存和磁盘之间存在访问时间差的分层缓存架构。Wang 等人采用基于效用的方法，将缓存问题建模为纳什讨价还价博弈。Chu等人在向内容提供商分配缓存资源时提出了一种效用驱动的缓存分区方法。
在本文中，我们使用 TTL 定时器作为单个
文件的调节旋钮，以控制相应内容所观察到的效用，并在不同内容之间实现缓存空间的公平使用。我们基于下一节描述的两种 TTL 缓存来 开发我们的框架。
表 I术语表
IV. 高速缓存效用最大化在本节中，我们将缓存管理表述为一个效用最大化问题
。我们引入了两种表述方式，一种是缓冲区大小固定不变，另一种是我们可以增加缓冲区大小，但会产生额外的存储成本。
A.固定缓存大小我们感兴趣的是设计一种缓存管理策略，它能更精确地优化所有文件的效用总和、
III.型号考虑一个大小为 B 的高速缓存，为一组 N 个文件提供服务。我们假设对文件 i 的请求是一个泊松过程，其速率为 λi 。此外，文件 i 的大小为 si 。让 hi 表示内容i 的命中概率。
(3)U (h) 假设为递增、连续可微分和严格凹形。请注意，具有这些性质的函数是可逆的。我们将处理不满足这些限制条件的效用函数是特例。
A. TTL 缓存在 TTL 缓存中，每个内容都与定时器 ti 相关联。每当内容 i 出现缓存缺失时，内容 i 就会被存储到缓存中，其定时器也会被设置为 ti 。定时器会以恒定的速率递减，当定时器为零时，内容就会被从缓存中删除。我们可以通过控制文件在缓存中的保留时间来调整文件的命中概率。
有两种 TTL 高速缓存设计：
非复位 TTL 高速缓存：仅在缓存未命中时设置 TTL即 TTL 不会在高速缓存命中时重置。
重置 TTL 缓存：每次请求内容时都会设置 TTL。
以前的 TTL 缓存分析工作表明，对于这两类非重置和重置 TTL 缓存，文件 i 的命中概率可表示为请注意，可行解集是凸的，由于目标函数是严格凹连续的，因此存在一个唯一的最大值，即最优解。还要注意的是，缓冲区约束是基于不超过缓冲区大小的预期文件数，而不是文件总数。在本节末尾，我们将展示缓冲区空间的管理方式，即当文件数和缓冲区大小增大时，违反缓冲区大小约束的概率将消失。
在上述表述中，效用被定义为文件命中概率的函数，即 Ui 。在第九节中，我们认为效用也可以定义为字节命中概率的函数，即 Ui 。ii
上述表述并不强制要求采用任何特殊技术来管理缓存内容，以达到所需的 hi s，而且可以采用任何能够轻松调整命中概率的策略。我们使用 TTL 缓存作为构建模块，因为它提供了通过设置定时器来控制不同文件命中概率的方法，从而使效用总和最大化。使用基于定时器的缓存技术来控制命中概率，0 < ti< 确保 0 < hi < 1，因此，不考虑 hi = 0 或 hi = 1的可能性。
(4)表 I 列出了本文所用主要符号的术语表，以帮助记号。
让 Ui′(-)表示效用函数的导数Ui (-)，并定义 U′−1 (-) 为其反函数。由 (4) 可知1 在本文中，我们将效用定义为高速缓存命中概率的函数。Panigrahy等人研究了将效用定义为命中率的函数。
(5)C. 违反缓冲区限制在结束本节讨论之前，我们先讨论一下在这两种公式中都会出现的一个问题，即如何处理以下事实应用缓存存储约束
(6)缓冲区中可能无法存储更多的未到期定时器内容。这种情况出现在 (3) 的表述中，因为约束条件是缓冲区的平均占用率，而 (4) 的表述则是缓冲区的平均占用率。
在 (9) 中，因为没有约束条件。让我们关注和 α 可以通过求解上面给出的定点方程计算出来。
如前所述，我们可以使用基于 TTL 的策略来实现效用最大化缓存。利用 (1) 和 (2) 中给出的非重置和重置 TTL缓存的命中概率表达式，我们可以计算出定时器参数 ti ，只要根据 (6) 确定了 α。对于非重置 TTL 缓存，我们可以得到
(3) 中的公式。我们的方法是提供一个大小为 B
、ϵ > 0 的缓冲区，其中一部分 B 用于解决优化问题，另一部分 ϵB 用于处理缓冲区违规问题。我们将看到，随着内容数量 N 的增加，我们可以让 B 以亚线性方式增长，并让ϵ 缩小为零，同时确保内容在其定时器到期前不会被高概率地从缓存中驱逐出去。让 Xi 表示是否内容 i 是否在缓存中；P  = h 。
对于重置 TTL 缓存，我们可以得到的函数，并假设 B(N) = ω(1)。
定理 1：假设 si ≤ smax , ∀i.对于任意 ϵ > 0
B. 弹性缓存大小
(3) 中的表述假定缓存容量是固定的。在某些情况下，服务提供商可以在以下位置增加可用的高速缓存存储空间证明来自切尔诺夫约束的应用。定理 1 指出，我们可以将缓冲区的大小设为 B，同时在优化过程中使用部分 B 作为约束条件。剩下的ϵB 部分用于防止违反缓冲区约束。就我们的目的而言，只要文件提供者需要为额外的资源支付一定的费用2 。在这种情况下，缓存容量限制可替换为
2 B(N)最大值ω(1).这样我们就可以选择B(N) = o(N) 而惩罚函数 C() 表示额外缓存存储的成本。这里，C()被假定为凸函数和递增函数。现在，我们可以将效用和成本驱动的缓存公式写成同时选择 ϵ = o(1)。举例说明齐普夫定律，λi = λ/iz ，λ > 0，0 < z < 1，i = 1，...，N，假设 max ti = t，对于某个 t < 。在这种情况下，我们可以以 B(N) = O 的方式增长缓冲区，而 ϵ 可以以 ϵ = 1/N/3 的方式缩小。
B)对于具有弹性的配方，也可以做出类似的选择。
V. 效用函数与公平在优化公式 (3) 中使用不同的效用函数，会产生不同的文件计时器值。从这个意义上说，每个效用函数都定义了为不同文件分配存储资源的公平性概念。
将上式两边乘以 si 并对所有 i 求和，我们就可以利用定点方程计算出缓存存储的最佳值 B∗ = i s h ii
其中系数 wi 0 表示文件 i 的权重。这个效用函数族统一了资源分配公平性的不同概念。
VII.
在线算法在第四节中，我们将效用驱动型缓存表述为一个凸优化问题，缓存大小可以是固定的，也可以是弹性的。然而，离线求解优化问题并实施最优策略并不可行。此外，系统参数会随着时间的推移而变化。因此，我们需要能通过收集有限信息来实施最优策略并适应系统变化的算法。在本节中，我们将开发这样的算法。
A. 双重解决方案问题(3)中提出的效用驱动缓存是一个凸优化问题，因此对偶差距为零，即求解对偶问题可以找到最优解。

